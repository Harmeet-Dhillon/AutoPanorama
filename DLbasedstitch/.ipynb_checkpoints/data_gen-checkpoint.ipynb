{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f9eec914-1165-4161-a165-7388d0026a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c84f47e0-e4fd-488c-a244-f41eb0bf38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_patchA(img,p,t,patch_size): # p = disturbance , t = translation\n",
    "    row,col=img.shape[:2]\n",
    "    #get the good coords for corner A ....assume corners of patch as ABCD \n",
    "    \n",
    "    clearance=int(1*(p+t))\n",
    "    colA=rand.randint(clearance,col-clearance-patch_size)\n",
    "    rowA=rand.randint(clearance,row-clearance-patch_size)\n",
    "    colB=colA+patch_size\n",
    "    rowB=rowA\n",
    "    colC=colA\n",
    "    rowC=rowA+patch_size\n",
    "    colD=colB\n",
    "    rowD=rowC\n",
    "    cornersA=[[rowA,colA],[rowB,colB],[rowC,colC],[rowD,colD],]\n",
    "    # print(\"cornersA\",cornersA)\n",
    "    return cornersA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "64d61eb6-ba37-476c-bf36-5901dc2ffc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disturbed_patch(img,corners,p,t):\n",
    "    cornersB=[]\n",
    "    for i,(row,col) in enumerate(corners):\n",
    "        row=row+rand.randint(-p,p)+rand.randint(-t,t)\n",
    "        col=col+rand.randint(-p,p)+rand.randint(-t,t)\n",
    "        corner=[row,col]\n",
    "        cornersB.append(corner)\n",
    "    #print(\" disturbed corners\",cornersB)\n",
    "    return cornersB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ccd1311-1a0b-4d51-9fd7-9c1a1b8d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowcol_to_colrow(list1):\n",
    "    return [[col, row] for row, col in list1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee34dda3-6bc2-4834-bfc4-1d08e7f48968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homography(img,cornersA,cornersB):\n",
    "    #getperspective takes input in form of x,y /col,row\n",
    "    h=cv2.getPerspectiveTransform(np.float32(rowcol_to_colrow(cornersA)), np.float32(rowcol_to_colrow(cornersB))) ###i m not sure about it why not this...\n",
    "    h=np.linalg.pinv(h)\n",
    "    ###will try doing this manually\n",
    "    #print('h',h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d6cbcf1-aec2-4535-a557-77658c4a8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(img,h):\n",
    "    # Get dimensions of img1 and img2\n",
    "    #this function perspective.transform also takes input in form of col,row\n",
    "    h1, w1 = img.shape[:2]\n",
    "\n",
    "    # Compute the warped corners of img1\n",
    "    '''\n",
    "    corners = np.array([[0, 0], [w1, 0], [w1, h1], [0, h1]], dtype=np.float32)\n",
    "    warped_corners = cv2.perspectiveTransform(corners[None, :, :], h)[0]\n",
    "    # Find the bounding box of the warped corners\n",
    "    x_min = warped_corners[:, 0].min()\n",
    "    y_min = warped_corners[:, 1].min()\n",
    "    x_max = warped_corners[:, 0].max()\n",
    "    y_max = warped_corners[:, 1].max()\n",
    "\n",
    "    # Compute the size of the new canvas\n",
    "    new_width = int(x_max - x_min)\n",
    "    new_height = int(y_max - y_min)\n",
    "    '''\n",
    "    # Compute the translation matrix to shift the content to fit in the canvas\n",
    "    #translation = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "\n",
    "    # Warp img1 onto the extended canvas\n",
    "    #extended_h = translation @ h  # Combine translation with the homography\n",
    "    warp_img = cv2.warpPerspective(img,h, (img.shape[1],img.shape[0]))\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c2d5a31-22d7-4c8c-9172-81a2a4cdbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_extraction(img, corners):  # corners in form of [row, col]\n",
    "    row_min = corners[0][0]\n",
    "    col_min = corners[0][1]\n",
    "    row_max = corners[3][0]  # Include the max row\n",
    "    col_max = corners[3][1] # Include the max col\n",
    "    patch_img = img[row_min:row_max, col_min:col_max]  # Correct slicing\n",
    "    return patch_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6b6c82ad-7ff1-4056-906c-28399a28cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(H,W,img1, img2, cornersA,cornersB):\n",
    "    #print(\"H,W\",H,W)\n",
    "    r = [90, 180, 270]\n",
    "    a = rand.randint(0, 2)  # Randomly select an index (0, 1, or 2)\n",
    "    #print(\"rotation\",r[a])\n",
    "    #print(\"cornersA cornersB no rotation\",cornersA,cornersB)\n",
    "    # Rotate the images anticlockwise\n",
    "    if r[a] == 90:\n",
    "        img1_rot = cv2.rotate(img1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        img2_rot = cv2.rotate(img2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    elif r[a] == 180:\n",
    "        img1_rot = cv2.rotate(img1, cv2.ROTATE_180)\n",
    "        img2_rot = cv2.rotate(img2, cv2.ROTATE_180)\n",
    "    elif r[a] == 270:\n",
    "        img1_rot = cv2.rotate(img1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        img2_rot = cv2.rotate(img2, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    # Now rotate the corners anticlockwise\n",
    "    for i in range(len(cornersA)):\n",
    "        row, col = cornersA[i]  # Unpack the corner into row and col\n",
    "        if r[a] == 90:\n",
    "            cornersA[i] = [W-1-col,row]  # 90° anticlockwise (or 270° clockwise)\n",
    "        elif r[a] == 180:\n",
    "            cornersA[i] = [H-1- row, W-1- col]  # 180° rotation\n",
    "        elif r[a] == 270:\n",
    "            cornersA[i] = [col, H-1-row]  # 270° anticlockwise (or 90° clockwise)\n",
    "    for i in range(len(cornersB)):\n",
    "        row, col = cornersB[i]  # Unpack the corner into row and col\n",
    "        if r[a] == 90:\n",
    "            cornersB[i] = [W-1-col, row]  # 90° anticlockwise (or 270° clockwise)\n",
    "        elif r[a] == 180:\n",
    "            cornersB[i] = [H-1- row, W-1- col]  # 180° rotation\n",
    "        elif r[a] == 270:\n",
    "            cornersB[i] = [col,H-1-row]  # 270° anticlockwise (or 90° clockwise)\n",
    "    \n",
    "    #print(\"cornersA cornersB after rotation\",cornersA,cornersB)\n",
    "\n",
    "    return img1_rot, img2_rot, cornersA,cornersB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f4d2f6a-a426-47bd-81b5-66f605837eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(img,p,t,patch_size):\n",
    "    cornersA=select_patchA(img,p,t,patch_size)\n",
    "    cornersB=disturbed_patch(img,cornersA,p,t)\n",
    "    \n",
    "    cA = np.array(cornersA, dtype=np.float32)  # Ensure float32\n",
    "    cB = np.array(cornersB, dtype=np.float32)  # Ensure float32\n",
    "    \n",
    "    H4pt=cB-cA\n",
    "    h=get_homography(img,cornersA,cornersB)\n",
    "    warped_img=warp_img(img,h)\n",
    "    img1=patch_extraction(img,cornersA)\n",
    "    img2=patch_extraction(warped_img,cornersA)\n",
    "    return img1,img2,H4pt,cornersA,cornersB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f3a99edd-4114-4dab-b936-8be2cd83e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory_rotated(H,W,img1,img2,cornersA,cornersB):\n",
    "    #cornersA=select_patchA(img,p,t,patch_size)\n",
    "    #cornersB=disturbed_patch(img,cornersA,p)\n",
    "    # rotationg by 90 , 180,270\n",
    "    \n",
    "    img1_rot,img2_rot,cornersA_new,cornersB_new=rotation(H,W,img1,img2,cornersA,cornersB)\n",
    "    \n",
    "    \n",
    "    cA = np.array(cornersA_new, dtype=np.float32)  # Ensure float32\n",
    "    cB = np.array(cornersB_new, dtype=np.float32)  # Ensure float32\n",
    "    \n",
    "    H4pt=cB-cA\n",
    "    return img1_rot,img2_rot,H4pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17f63c6b-a1aa-4014-8cde-05aa28e4480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_main(img, p, t, patch_size):\n",
    "    img1, img2 = data_factory(img, p, t, patch_size)\n",
    "\n",
    "    # Convert images to PyTorch tensors\n",
    "    img1_tensor = torch.tensor(img1, dtype=torch.float32).permute(2, 0, 1)  # (H, W, C) -> (C, H, W)\n",
    "    img2_tensor = torch.tensor(img2, dtype=torch.float32).permute(2, 0, 1)  \n",
    "\n",
    "    # Stack tensors into shape (2, 3, patch_height, patch_width)\n",
    "    final_tensor = torch.stack([img1_tensor, img2_tensor], dim=0)  \n",
    "\n",
    "    return final_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "33036efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (213558506.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[126], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_data(src_imgs_path, dst_imgs_path, dst_txt_path,val=False):\n",
    "    \"\"\"\n",
    "    dst_imgs_path: Path to folder containing images to extract and create patches from\n",
    "    dst_txt_path: Path to folder to store txt labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directories for storing results\n",
    "    os.makedirs(f\"{dst_imgs_path}/A\", exist_ok=True)\n",
    "    os.makedirs(f\"{dst_imgs_path}/B\", exist_ok=True)\n",
    "    os.makedirs(dst_txt_path, exist_ok=True)\n",
    "\n",
    "    # Paths to text files\n",
    "    labels_file = f\"{dst_txt_path}/Labels.txt\"\n",
    "    dirA_file   = f\"{dst_txt_path}/DirNamesA.txt\"\n",
    "    dirB_file   = f\"{dst_txt_path}/DirNamesB.txt\"\n",
    "\n",
    "    # Ensure the text files exist\n",
    "    if not os.path.exists(labels_file):\n",
    "        open(labels_file, 'w').close()\n",
    "    if not os.path.exists(dirA_file):\n",
    "        open(dirA_file, 'w').close()\n",
    "    if not os.path.exists(dirB_file):\n",
    "        open(dirB_file, 'w').close()\n",
    "\n",
    "    # Get all images from the source folder\n",
    "    # img_files = glob.glob(\"./Data/Train/*.jpg\")\n",
    "    img_files = glob.glob(src_imgs_path+\"/*.jpg\")\n",
    "\n",
    "    # Sort the list of image files to ensure ordered processing\n",
    "    img_files.sort(key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    p = 32 # disturbance\n",
    "    t = 0 # translation\n",
    "    patch_size = 128\n",
    "\n",
    "    # Open label and DirNames files for writing\n",
    "    with open(labels_file, \"w\") as f_labels, open(dirA_file, \"w\") as f_A, open(dirB_file, \"w\") as f_B:\n",
    "        print(\"Opened files\")\n",
    "        for index in range(3):\n",
    "            if val and index>0:\n",
    "                continue\n",
    "            for img_path in tqdm(img_files, desc=\"Processing Images\"):\n",
    "                \n",
    "                # Read image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Error loading {img_path}\")\n",
    "                    continue\n",
    "    \n",
    "                h, w = img.shape[:2]\n",
    "                if min(h, w) < 240:\n",
    "                    p = min(h, w) // 25\n",
    "                    # print(\"p\", p)\n",
    "                    \n",
    "                img_name = os.path.basename(img_path).split('.')[0]\n",
    "                \n",
    "                img_name=str(int(img_name)+index*5000)\n",
    "                \n",
    "                # Process image to get patches and homography\n",
    "                img1, img2, H4pt,cornersA,cornersB = data_factory(img, p, t, patch_size)\n",
    "                \n",
    "                cv2.imwrite(f\"{dst_imgs_path}/A/{img_name}.jpg\", img1)\n",
    "                cv2.imwrite(f\"{dst_imgs_path}/B/{img_name}.jpg\", img2)\n",
    "                \n",
    "                f_A.write(f\"{dst_imgs_path}/A/{img_name}\\n\")\n",
    "                f_B.write(f\"{dst_imgs_path}/B/{img_name}\\n\")\n",
    "                \n",
    "                \n",
    "                    \n",
    "    \n",
    "                # Convert H4pt from 4x2 to a single-row array (1x8)\n",
    "                H4pt_flat = H4pt.flatten()\n",
    "                H4pt_str = \" \".join(map(str, H4pt_flat))  # Convert array to space-separated string\n",
    "    \n",
    "                # Save the labels in the text file\n",
    "                f_labels.write(f\"{img_name} {H4pt_str}\\n\") \n",
    "                \n",
    "                if index==2 and not val:\n",
    "                    img1_rot,img2_rot,H4pt_rot=data_factory_rotated(h,w,img1,img2,cornersA,cornersB)\n",
    "                    img_name_rot = os.path.basename(img_path).split('.')[0]\n",
    "                    img_name_rot=str(int(img_name_rot)+(index+1)*5000)\n",
    "                    \n",
    "        \n",
    "                    # Save img1 in folder A and img2 in folder B\n",
    "                    cv2.imwrite(f\"{dst_imgs_path}/A/{img_name_rot}.jpg\", img1_rot)\n",
    "                    cv2.imwrite(f\"{dst_imgs_path}/B/{img_name_rot}.jpg\", img2_rot)\n",
    "        \n",
    "                    # Write the paths to DirNamesTrainA and DirNamesTrainB without the .jpg extension\n",
    "                    f_A.write(f\"{dst_imgs_path}/A/{img_name_rot}\\n\")\n",
    "                    f_B.write(f\"{dst_imgs_path}/B/{img_name_rot}\\n\")\n",
    "        \n",
    "                    # Convert H4pt from 4x2 to a single-row array (1x8)\n",
    "                    H4pt_flat_rot = H4pt_rot.flatten()\n",
    "                    H4pt_str_rot = \" \".join(map(str, H4pt_flat_rot))  # Convert array to space-separated string\n",
    "        \n",
    "                    # Save the labels in the text file\n",
    "                    f_labels.write(f\"{img_name_rot} {H4pt_str_rot}\\n\") \n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "87eab08f-b465-463a-b833-559e9d550a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_data(src_imgs_path, dst_imgs_path, dst_txt_path,val=False):\n",
    "    \"\"\"\n",
    "    dst_imgs_path: Path to folder containing images to extract and create patches from\n",
    "    dst_txt_path: Path to folder to store txt labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directories for storing results\n",
    "    os.makedirs(f\"{dst_imgs_path}/A\", exist_ok=True)\n",
    "    os.makedirs(f\"{dst_imgs_path}/B\", exist_ok=True)\n",
    "    os.makedirs(dst_txt_path, exist_ok=True)\n",
    "\n",
    "    # Paths to text files\n",
    "    labels_file = f\"{dst_txt_path}/Labels.txt\"\n",
    "    dirA_file   = f\"{dst_txt_path}/DirNamesA.txt\"\n",
    "    dirB_file   = f\"{dst_txt_path}/DirNamesB.txt\"\n",
    "\n",
    "    # Ensure the text files exist\n",
    "    if not os.path.exists(labels_file):\n",
    "        open(labels_file, 'w').close()\n",
    "    if not os.path.exists(dirA_file):\n",
    "        open(dirA_file, 'w').close()\n",
    "    if not os.path.exists(dirB_file):\n",
    "        open(dirB_file, 'w').close()\n",
    "\n",
    "    # Get all images from the source folder\n",
    "    # img_files = glob.glob(\"./Data/Train/*.jpg\")\n",
    "    img_files = glob.glob(src_imgs_path+\"/*.jpg\")\n",
    "\n",
    "    # Sort the list of image files to ensure ordered processing\n",
    "    img_files.sort(key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    p = 32 # disturbance\n",
    "    t = 20 # translation\n",
    "    patch_size = 128\n",
    "\n",
    "    # Open label and DirNames files for writing\n",
    "    with open(labels_file, \"w\") as f_labels, open(dirA_file, \"w\") as f_A, open(dirB_file, \"w\") as f_B:\n",
    "        print(\"Opened files\")\n",
    "        for index in range(3):\n",
    "            if val and index>0:\n",
    "                continue\n",
    "            for img_path in tqdm(img_files, desc=\"Processing Images\"):\n",
    "                \n",
    "                # Read image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Error loading {img_path}\")\n",
    "                    continue\n",
    "    \n",
    "                h, w = img.shape[:2]\n",
    "                if min(h, w) < 240:\n",
    "                    p = min(h, w) // 25\n",
    "                    # print(\"p\", p)\n",
    "                    \n",
    "                img_name = os.path.basename(img_path).split('.')[0]\n",
    "                \n",
    "                img_name=str(int(img_name)+index*5000)\n",
    "                \n",
    "                # Process image to get patches and homography\n",
    "                img1, img2, H4pt,cornersA,cornersB = data_factory(img, p, t, patch_size)\n",
    "                \n",
    "                cv2.imwrite(f\"{dst_imgs_path}/A/{img_name}.jpg\", img1)\n",
    "                cv2.imwrite(f\"{dst_imgs_path}/B/{img_name}.jpg\", img2)\n",
    "                \n",
    "                f_A.write(f\"{dst_imgs_path}/A/{img_name}\\n\")\n",
    "                f_B.write(f\"{dst_imgs_path}/B/{img_name}\\n\")\n",
    "                \n",
    "                \n",
    "                    \n",
    "    \n",
    "                # Convert H4pt from 4x2 to a single-row array (1x8)\n",
    "                H4pt_flat = H4pt.flatten()\n",
    "                H4pt_str = \" \".join(map(str, H4pt_flat))  # Convert array to space-separated string\n",
    "    \n",
    "                # Save the labels in the text file\n",
    "                f_labels.write(f\"{img_name} {H4pt_str}\\n\") \n",
    "                \n",
    "                if index==2 and not val:\n",
    "                    img1_rot,img2_rot,H4pt_rot=data_factory_rotated(h,w,img1,img2,cornersA,cornersB)\n",
    "                    img_name_rot = os.path.basename(img_path).split('.')[0]\n",
    "                    img_name_rot=str(int(img_name_rot)+(index+1)*5000)\n",
    "                    \n",
    "        \n",
    "                    # Save img1 in folder A and img2 in folder B\n",
    "                    cv2.imwrite(f\"{dst_imgs_path}/A/{img_name_rot}.jpg\", img1_rot)\n",
    "                    cv2.imwrite(f\"{dst_imgs_path}/B/{img_name_rot}.jpg\", img2_rot)\n",
    "        \n",
    "                    # Write the paths to DirNamesTrainA and DirNamesTrainB without the .jpg extension\n",
    "                    f_A.write(f\"{dst_imgs_path}/A/{img_name_rot}\\n\")\n",
    "                    f_B.write(f\"{dst_imgs_path}/B/{img_name_rot}\\n\")\n",
    "        \n",
    "                    # Convert H4pt from 4x2 to a single-row array (1x8)\n",
    "                    H4pt_flat_rot = H4pt_rot.flatten()\n",
    "                    H4pt_str_rot = \" \".join(map(str, H4pt_flat_rot))  # Convert array to space-separated string\n",
    "        \n",
    "                    # Save the labels in the text file\n",
    "                    f_labels.write(f\"{img_name_rot} {H4pt_str_rot}\\n\") \n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "458b01f8-40d8-4601-bb43-b1e10b383d18",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2787193267.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[128], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def sort_file_entries(input_file, output_file):\n",
    "    # Read the file and extract all entries\n",
    "    with open(input_file, 'r') as file:\n",
    "        entries = file.readlines()\n",
    "\n",
    "    # Sort entries based on the number after the last '/' in the filename\n",
    "    sorted_entries = sorted(entries, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "    # Write the sorted entries back to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(sorted_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "05460726-de03-4349-874a-558aa4faacfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (93175514.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[129], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def sort_file_byfirstnumber(input_file, output_file):\n",
    "    # Read the file and extract all entries\n",
    "    with open(input_file, 'r') as file:\n",
    "        entries = file.readlines()\n",
    "\n",
    "    # Sort entries based on the first number in each line\n",
    "    sorted_entries = sorted(entries, key=lambda x: int(x.split()[0]))\n",
    "\n",
    "    # Write the sorted entries back to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(sorted_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "49a8a779-a39e-4309-9f86-76c4943412cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Training\n",
    "\n",
    "    print(\"Creating training data\")\n",
    "\n",
    "    train_src_images = \"./Data/Trainee\"\n",
    "    train_dst_images_path = \"./Data/Trainee/Patches\"\n",
    "    train_dst_text_path = \"./Data/Trainee/TxtFiles\"\n",
    "    \n",
    "    generate_data(train_src_images, train_dst_images_path, train_dst_text_path)\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    print(\"Creating validation data\")\n",
    "\n",
    "    val_src_images = \"./Data/Valee\"\n",
    "    val_dst_images_path = \"./Data/Valee/Patches\"\n",
    "    val_dst_text_path = \"./Data/Valee/TxtFiles\"\n",
    "\n",
    "    generate_data(val_src_images, val_dst_images_path, val_dst_text_path,val=True)\n",
    "    \n",
    "    # # Example usage\n",
    "    # input_file1 = f\"{train_dst_text_path}/UnsortDirNamesA.txt\"\n",
    "    # output_file1 =f\"{train_dst_text_path}/DirNamesA.txt\"\n",
    "    # input_file2 = f\"{train_dst_text_path}/UnsortDirNamesB.txt\"\n",
    "    # output_file2 =f\"{train_dst_text_path}/DirNamesB.txt\"\n",
    "    # input_file2 = f\"{train_dst_text_path}/UnsortLabels.txt\"\n",
    "    # output_file2 =f\"{train_dst_text_path}/Labels.txt\"\n",
    "    \n",
    "    \n",
    "    # sort_file_entries(input_file1, output_file1)\n",
    "    # sort_file_entries(input_file2,output_file2)\n",
    "    # sort_file_byfirstnumber(input_file3,output_file3)\n",
    "    \n",
    "    # print(\"Sorting completed and saved to:\", output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba64297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data\n",
      "Opened files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|████████████████████████| 28/28 [00:00<00:00, 93.95it/s]\n",
      "Processing Images: 100%|███████████████████████| 28/28 [00:00<00:00, 111.87it/s]\n",
      "Processing Images: 100%|████████████████████████| 28/28 [00:00<00:00, 97.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation data\n",
      "Opened files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|█████████████████████████| 4/4 [00:00<00:00, 110.49it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e8d14-a766-40e6-9764-45bb6ba871e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ef845-d15b-42f2-82c1-a4ce1de0c59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
